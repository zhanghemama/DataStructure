极客时间学习笔记之归并排序快速排序，

#
归并排序的核心思想是，先把数组分成两部分，然后分别排序，再将排好序的两个部分合并，这样整个数组就有序了；
归并排序使用的是分治思想，将一个大问题分解成子问题来解决，子问题解决了，大问题也随之解决了；分治思想
跟我们前面学到的递归很像，分治算法一般都用递归实现；分治是一种处理问题的思想，递归是一种编程技巧；
归并排序的递推公式是，
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：
p >= r 不用再继续分解

#
归并排序的性能分析，
1.归并排序是一种稳定的排序算法，归并排序稳不稳定关键取决于merge函数，值相等的元素merge的时候先后顺序保持
不变；
2.归并排序的时间复杂度O(nlogn),可以用以下公式来推导，
T(1) = C；   n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1

T(n) = 2*T(n/2) + n
= 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
= 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
= 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
......
= 2^k * T(n/2^k) + k * n
......

3.归并排序不是原地排序，这也是它没有被广泛应用的原因，归并排序中在任一时刻，CPU中只会有一个函数运行，临时空间
最大不超过n，所以空间复杂度是O(n).

#
快速排序，核心思想是在数组中选取一个分区点，小于它的排左边，大于它的排右边；递推公式如下，
递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)

终止条件：
p >= r

归并排序有个merge函数，快速排序有个分区函数，分区函数就是选取分区点，小于分区点排左边，大于分区点排右边；
它的空间复杂度要达到O(1),实现思路很巧妙，
partition(A, p, r) {
pivot := A[r]
i := p
for j := p to r-1 do {
if A[j] < pivot {
swap A[i] with A[j]
i := i+1
}
}
swap A[i] with A[r]
return i

#归并排序和快速排序的区别，
归并排序是先处理子问题再merge，由下到上，快速排序是先分区再处理子问题，由上到下；归并排序和快速排序的时间
复杂度相同，但是归并排序不是原地排序，快速排序巧妙利用分区，可以实现原地排序，解决了归并排序占用内存多的问题。
快速排序不是稳定的排序算法。

#应用，查找数组中第k大元素
利用分治的思想，选取分区点将数组分成三部分，p--q-1，q， q+1--r，如果q == k则q位置的元素就是第k大元素，如果
q<k,则在后半部分查找，否则在前半部分查找；
这个查找的时间复杂度是O(n),我们总共需要遍历的元素，n， n/2， n/4， n/8，直到区间缩小为1，这个是等比数列，和为
2*n-1，所以时间复杂度是O(n).

#课后思考题，
现在有10个接口访问日志文件，每个文件大概300m，每个文件都是按照时间戳从大到小排好序的。你希望这10个较小的文件，
合并成一个日志文件，合并之后日志仍然按照时间戳排序。假设机器的内存只有1G，应该怎么解决？
先构建10条io流，分别指向10个文件，每条io流读取对应文件的第一条数据，然后比较时间戳，选择出时间戳最小的那条数据，
将其写入一个新文件，然后指向该时间戳的io流读取下一条数据，然后继续刚才的操作，比较选择出时间戳最小的数据，写入文件，依次类推，完成文件的操作；



